// ä¸Šä¼ ç®¡ç†å™¨
//
// è´Ÿè´£ç®¡ç†å¤šä¸ªä¸Šä¼ ä»»åŠ¡ï¼š
// - ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
// - å¹¶å‘æ§åˆ¶ï¼ˆæ”¯æŒè°ƒåº¦å™¨æ¨¡å¼å’Œç‹¬ç«‹æ¨¡å¼ï¼‰
// - è¿›åº¦è·Ÿè¸ª
// - æš‚åœ/æ¢å¤/å–æ¶ˆ
//
//  æ”¯æŒå…¨å±€è°ƒåº¦å™¨æ¨¡å¼
// - å¤šä»»åŠ¡å…¬å¹³è°ƒåº¦
// - å…¨å±€å¹¶å‘æ§åˆ¶
// - é¢„æ³¨å†Œæœºåˆ¶

use crate::auth::UserAuth;
use crate::config::{UploadConfig, VipType};
use crate::netdisk::NetdiskClient;
use crate::uploader::{
    calculate_upload_task_max_chunks, FolderScanner, PcsServerHealthManager, ScanOptions,
    UploadChunkManager, UploadChunkScheduler, UploadEngine, UploadTask, UploadTaskScheduleInfo,
    UploadTaskStatus,
};
use anyhow::{Context, Result};
use dashmap::DashMap;
use std::collections::VecDeque;
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::{Mutex, RwLock, Semaphore};
use tokio_util::sync::CancellationToken;
use tracing::{error, info, warn};

/// ä¸Šä¼ ä»»åŠ¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒåº¦ï¼‰
#[derive(Debug, Clone)]
pub struct UploadTaskInfo {
    /// ä»»åŠ¡
    pub task: Arc<Mutex<UploadTask>>,
    /// åˆ†ç‰‡ç®¡ç†å™¨
    pub chunk_manager: Arc<Mutex<UploadChunkManager>>,
    /// å–æ¶ˆä»¤ç‰Œ
    pub cancel_token: CancellationToken,
    /// æœ€å¤§å¹¶å‘åˆ†ç‰‡æ•°ï¼ˆæ ¹æ®æ–‡ä»¶å¤§å°è®¡ç®—ï¼‰
    pub max_concurrent_chunks: usize,
    /// å½“å‰æ´»è·ƒåˆ†ç‰‡æ•°
    pub active_chunk_count: Arc<AtomicUsize>,
    /// æ˜¯å¦æš‚åœ
    pub is_paused: Arc<AtomicBool>,
    /// å·²ä¸Šä¼ å­—èŠ‚æ•°ï¼ˆç”¨äºè°ƒåº¦å™¨æ¨¡å¼ï¼‰
    pub uploaded_bytes: Arc<AtomicU64>,
    /// ä¸Šæ¬¡é€Ÿåº¦è®¡ç®—æ—¶é—´
    pub last_speed_time: Arc<Mutex<std::time::Instant>>,
    /// ä¸Šæ¬¡é€Ÿåº¦è®¡ç®—å­—èŠ‚æ•°
    pub last_speed_bytes: Arc<AtomicU64>,
}

/// ä¸Šä¼ ç®¡ç†å™¨
pub struct UploadManager {
    /// ç½‘ç›˜å®¢æˆ·ç«¯
    client: NetdiskClient,
    /// ç”¨æˆ· VIP ç±»å‹
    vip_type: VipType,
    /// æ‰€æœ‰ä»»åŠ¡ï¼ˆtask_id -> TaskInfoï¼‰- ä½¿ç”¨ Arc åŒ…è£…ä»¥æ”¯æŒè·¨çº¿ç¨‹å…±äº«
    tasks: Arc<DashMap<String, UploadTaskInfo>>,
    /// ç­‰å¾…é˜Ÿåˆ—ï¼ˆtask_id åˆ—è¡¨ï¼ŒFIFOï¼‰
    waiting_queue: Arc<RwLock<VecDeque<String>>>,
    /// å…¨å±€å¹¶å‘æ§åˆ¶ä¿¡å·é‡ï¼ˆç”¨äºç‹¬ç«‹æ¨¡å¼ï¼‰
    #[allow(dead_code)]
    global_semaphore: Arc<Semaphore>,
    /// æœåŠ¡å™¨å¥åº·ç®¡ç†å™¨
    server_health: Arc<PcsServerHealthManager>,
    /// å…¨å±€è°ƒåº¦å™¨ï¼ˆï¼‰
    scheduler: Option<Arc<UploadChunkScheduler>>,
    /// æ˜¯å¦ä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼
    use_scheduler: bool,
    /// æœ€å¤§åŒæ—¶ä¸Šä¼ ä»»åŠ¡æ•°ï¼ˆåŠ¨æ€å¯è°ƒæ•´ï¼‰
    max_concurrent_tasks: Arc<AtomicUsize>,
    /// æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆåŠ¨æ€å¯è°ƒæ•´ï¼‰
    max_retries: Arc<AtomicUsize>,
}

impl UploadManager {
    /// åˆ›å»ºæ–°çš„ä¸Šä¼ ç®¡ç†å™¨ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    pub fn new(client: NetdiskClient, user_auth: &UserAuth) -> Self {
        Self::new_with_config(client, user_auth, &UploadConfig::default())
    }

    /// åˆ›å»ºä¸Šä¼ ç®¡ç†å™¨ï¼ˆä»é…ç½®è¯»å–å‚æ•°ï¼‰
    ///
    /// # å‚æ•°
    /// * `client` - ç½‘ç›˜å®¢æˆ·ç«¯
    /// * `user_auth` - ç”¨æˆ·è®¤è¯ä¿¡æ¯
    /// * `config` - ä¸Šä¼ é…ç½®
    pub fn new_with_config(client: NetdiskClient, user_auth: &UserAuth, config: &UploadConfig) -> Self {
        Self::new_with_full_options(client, user_auth, config, true)
    }

    /// åˆ›å»ºä¸Šä¼ ç®¡ç†å™¨ï¼ˆå®Œæ•´é€‰é¡¹ï¼‰
    ///
    /// # å‚æ•°
    /// * `client` - ç½‘ç›˜å®¢æˆ·ç«¯
    /// * `user_auth` - ç”¨æˆ·è®¤è¯ä¿¡æ¯
    /// * `config` - ä¸Šä¼ é…ç½®
    /// * `use_scheduler` - æ˜¯å¦ä½¿ç”¨å…¨å±€è°ƒåº¦å™¨æ¨¡å¼
    pub fn new_with_full_options(client: NetdiskClient, user_auth: &UserAuth, config: &UploadConfig, use_scheduler: bool) -> Self {
        let max_global_threads = config.max_global_threads;
        let max_concurrent_tasks = config.max_concurrent_tasks;
        let max_retries = config.max_retries as usize;

        // ä» user_auth è·å– VIP ç±»å‹
        let vip_type = VipType::from_u32(user_auth.vip_type.unwrap_or(0));

        // åˆ›å»ºæœåŠ¡å™¨å¥åº·ç®¡ç†å™¨
        let servers = vec![
            "d.pcs.baidu.com".to_string(),
            "c.pcs.baidu.com".to_string(),
            "pcs.baidu.com".to_string(),
        ];
        let server_health = Arc::new(PcsServerHealthManager::from_servers(servers));

        // åˆ›å»ºè°ƒåº¦å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        let scheduler = if use_scheduler {
            info!("ä¸Šä¼ ç®¡ç†å™¨ä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼: å…¨å±€çº¿ç¨‹æ•°={}, æœ€å¤§ä»»åŠ¡æ•°={}, æœ€å¤§é‡è¯•={}",
                max_global_threads, max_concurrent_tasks, max_retries);
            Some(Arc::new(UploadChunkScheduler::new_with_config(
                max_global_threads,
                max_concurrent_tasks,
                max_retries as u32,
            )))
        } else {
            info!("ä¸Šä¼ ç®¡ç†å™¨ä½¿ç”¨ç‹¬ç«‹æ¨¡å¼: å…¨å±€çº¿ç¨‹æ•°={}, æœ€å¤§ä»»åŠ¡æ•°={}, æœ€å¤§é‡è¯•={}",
                max_global_threads, max_concurrent_tasks, max_retries);
            None
        };

        let waiting_queue = Arc::new(RwLock::new(VecDeque::new()));
        let max_concurrent_tasks_atomic = Arc::new(AtomicUsize::new(max_concurrent_tasks));
        let max_retries_atomic = Arc::new(AtomicUsize::new(max_retries));

        let tasks = Arc::new(DashMap::new());

        let manager = Self {
            client,
            vip_type,
            tasks: tasks.clone(),
            waiting_queue: waiting_queue.clone(),
            global_semaphore: Arc::new(Semaphore::new(max_global_threads)),
            server_health,
            scheduler: scheduler.clone(),
            use_scheduler,
            max_concurrent_tasks: max_concurrent_tasks_atomic,
            max_retries: max_retries_atomic,
        };

        // å¯åŠ¨åå°ä»»åŠ¡ï¼šå®šæœŸæ£€æŸ¥å¹¶å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        if use_scheduler {
            manager.start_waiting_queue_monitor();
        }

        manager
    }

    /// åŠ¨æ€æ›´æ–°æœ€å¤§å…¨å±€çº¿ç¨‹æ•°
    pub fn update_max_threads(&self, new_max: usize) {
        if let Some(scheduler) = &self.scheduler {
            scheduler.update_max_threads(new_max);
        }
        info!("ğŸ”§ ä¸Šä¼ ç®¡ç†å™¨: åŠ¨æ€è°ƒæ•´å…¨å±€æœ€å¤§çº¿ç¨‹æ•°ä¸º {}", new_max);
    }

    /// åŠ¨æ€æ›´æ–°æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    pub fn update_max_concurrent_tasks(&self, new_max: usize) {
        self.max_concurrent_tasks.store(new_max, Ordering::SeqCst);
        if let Some(scheduler) = &self.scheduler {
            scheduler.update_max_concurrent_tasks(new_max);
        }
        info!("ğŸ”§ ä¸Šä¼ ç®¡ç†å™¨: åŠ¨æ€è°ƒæ•´æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ä¸º {}", new_max);
    }

    /// åŠ¨æ€æ›´æ–°æœ€å¤§é‡è¯•æ¬¡æ•°
    pub fn update_max_retries(&self, new_max: u32) {
        self.max_retries.store(new_max as usize, Ordering::SeqCst);
        if let Some(scheduler) = &self.scheduler {
            scheduler.update_max_retries(new_max);
        }
        info!("ğŸ”§ ä¸Šä¼ ç®¡ç†å™¨: åŠ¨æ€è°ƒæ•´æœ€å¤§é‡è¯•æ¬¡æ•°ä¸º {}", new_max);
    }

    /// è·å–å½“å‰æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    pub fn max_concurrent_tasks(&self) -> usize {
        self.max_concurrent_tasks.load(Ordering::SeqCst)
    }

    /// è·å–å½“å‰æœ€å¤§é‡è¯•æ¬¡æ•°
    pub fn max_retries(&self) -> u32 {
        self.max_retries.load(Ordering::SeqCst) as u32
    }

    /// è·å–è°ƒåº¦å™¨å¼•ç”¨
    pub fn scheduler(&self) -> Option<Arc<UploadChunkScheduler>> {
        self.scheduler.clone()
    }

    /// åˆ›å»ºä¸Šä¼ ä»»åŠ¡
    ///
    /// # å‚æ•°
    /// * `local_path` - æœ¬åœ°æ–‡ä»¶è·¯å¾„
    /// * `remote_path` - ç½‘ç›˜ç›®æ ‡è·¯å¾„
    ///
    /// # è¿”å›
    /// ä»»åŠ¡ID
    pub async fn create_task(&self, local_path: PathBuf, remote_path: String) -> Result<String> {
        // è·å–æ–‡ä»¶å¤§å°
        let metadata = tokio::fs::metadata(&local_path)
            .await
            .context(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {:?}", local_path))?;

        if metadata.is_dir() {
            return Err(anyhow::anyhow!(
                "ä¸æ”¯æŒç›´æ¥ä¸Šä¼ ç›®å½•ï¼Œè¯·ä½¿ç”¨ create_folder_task"
            ));
        }

        let file_size = metadata.len();

        // åˆ›å»ºä»»åŠ¡
        let task = UploadTask::new(local_path.clone(), remote_path.clone(), file_size);
        let task_id = task.id.clone();

        // åˆ›å»ºåˆ†ç‰‡ç®¡ç†å™¨ï¼ˆä½¿ç”¨ç”¨æˆ·çš„ VIP ç­‰çº§è®¡ç®—åˆ†ç‰‡å¤§å°ï¼‰
        let chunk_manager = UploadChunkManager::with_vip_type(file_size, self.vip_type);

        // è®¡ç®—æœ€å¤§å¹¶å‘åˆ†ç‰‡æ•°
        let max_concurrent_chunks = calculate_upload_task_max_chunks(file_size);

        info!(
            "åˆ›å»ºä¸Šä¼ ä»»åŠ¡: id={}, local={:?}, remote={}, size={}, chunks={}, max_concurrent={}",
            task_id,
            local_path,
            remote_path,
            file_size,
            chunk_manager.chunk_count(),
            max_concurrent_chunks
        );

        // ä¿å­˜ä»»åŠ¡ä¿¡æ¯
        let task_info = UploadTaskInfo {
            task: Arc::new(Mutex::new(task)),
            chunk_manager: Arc::new(Mutex::new(chunk_manager)),
            cancel_token: CancellationToken::new(),
            max_concurrent_chunks,
            active_chunk_count: Arc::new(AtomicUsize::new(0)),
            is_paused: Arc::new(AtomicBool::new(false)),
            uploaded_bytes: Arc::new(AtomicU64::new(0)),
            last_speed_time: Arc::new(Mutex::new(std::time::Instant::now())),
            last_speed_bytes: Arc::new(AtomicU64::new(0)),
        };

        self.tasks.insert(task_id.clone(), task_info);

        Ok(task_id)
    }

    /// æ‰¹é‡åˆ›å»ºä¸Šä¼ ä»»åŠ¡
    pub async fn create_batch_tasks(
        &self,
        files: Vec<(PathBuf, String)>,
    ) -> Result<Vec<String>> {
        let mut task_ids = Vec::with_capacity(files.len());

        for (local_path, remote_path) in files {
            match self.create_task(local_path.clone(), remote_path).await {
                Ok(task_id) => {
                    task_ids.push(task_id);
                }
                Err(e) => {
                    warn!("åˆ›å»ºä»»åŠ¡å¤±è´¥: {:?}, é”™è¯¯: {}", local_path, e);
                }
            }
        }

        Ok(task_ids)
    }

    /// åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡
    ///
    /// # å‚æ•°
    /// * `local_folder` - æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„
    /// * `remote_folder` - ç½‘ç›˜ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
    /// * `scan_options` - æ‰«æé€‰é¡¹ï¼ˆå¯é€‰ï¼‰
    ///
    /// # è¿”å›
    /// æ‰€æœ‰åˆ›å»ºçš„ä»»åŠ¡IDåˆ—è¡¨
    ///
    /// # è¯´æ˜
    /// - ä¼šé€’å½’æ‰«ææœ¬åœ°æ–‡ä»¶å¤¹
    /// - ä¿æŒç›®å½•ç»“æ„
    /// - è‡ªåŠ¨åˆ›å»ºæ‰¹é‡ä¸Šä¼ ä»»åŠ¡
    pub async fn create_folder_task<P: AsRef<Path>>(
        &self,
        local_folder: P,
        remote_folder: String,
        scan_options: Option<ScanOptions>,
    ) -> Result<Vec<String>> {
        let local_folder = local_folder.as_ref();

        info!(
            "å¼€å§‹åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡: local={:?}, remote={}",
            local_folder, remote_folder
        );

        // ä½¿ç”¨æ–‡ä»¶å¤¹æ‰«æå™¨æ‰«ææ–‡ä»¶
        let scanner = if let Some(options) = scan_options {
            FolderScanner::with_options(options)
        } else {
            FolderScanner::new()
        };

        let scanned_files = scanner.scan(local_folder)?;

        if scanned_files.is_empty() {
            return Err(anyhow::anyhow!("æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–æ— å¯ä¸Šä¼ æ–‡ä»¶"));
        }

        info!(
            "æ‰«æåˆ° {} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹åˆ›å»ºä¸Šä¼ ä»»åŠ¡",
            scanned_files.len()
        );

        // å‡†å¤‡æ‰¹é‡ä»»åŠ¡
        let mut tasks = Vec::with_capacity(scanned_files.len());

        for file in scanned_files {
            // æ„å»ºè¿œç¨‹è·¯å¾„ï¼šremote_folder + relative_path
            let remote_path = if remote_folder.ends_with('/') {
                format!(
                    "{}{}",
                    remote_folder,
                    file.relative_path.to_string_lossy()
                )
            } else {
                format!(
                    "{}/{}",
                    remote_folder,
                    file.relative_path.to_string_lossy()
                )
            };

            // ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦ä¸º Unix é£æ ¼ï¼ˆç™¾åº¦ç½‘ç›˜ä½¿ç”¨ /ï¼‰
            let remote_path = remote_path.replace('\\', "/");

            tasks.push((file.local_path, remote_path));
        }

        // æ‰¹é‡åˆ›å»ºä»»åŠ¡
        let task_ids = self.create_batch_tasks(tasks).await?;

        info!(
            "æ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡åˆ›å»ºå®Œæˆ: æˆåŠŸ {} ä¸ª",
            task_ids.len()
        );

        Ok(task_ids)
    }

    /// å¼€å§‹ä¸Šä¼ ä»»åŠ¡
    ///
    /// æ ¹æ® `use_scheduler` é…ç½®é€‰æ‹©æ‰§è¡Œæ¨¡å¼ï¼š
    /// - è°ƒåº¦å™¨æ¨¡å¼ï¼šå°†ä»»åŠ¡æ³¨å†Œåˆ°å…¨å±€è°ƒåº¦å™¨ï¼Œç”±è°ƒåº¦å™¨ç»Ÿä¸€è°ƒåº¦
    /// - ç‹¬ç«‹æ¨¡å¼ï¼šç›´æ¥å¯åŠ¨ UploadEngine æ‰§è¡Œä¸Šä¼ 
    pub async fn start_task(&self, task_id: &str) -> Result<()> {
        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        // æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        let (local_path, remote_path, total_size) = {
            let task = task_info.task.lock().await;
            match task.status {
                UploadTaskStatus::Pending | UploadTaskStatus::Paused => {}
                UploadTaskStatus::Uploading | UploadTaskStatus::CheckingRapid => {
                    return Err(anyhow::anyhow!("ä»»åŠ¡å·²åœ¨ä¸Šä¼ ä¸­"));
                }
                UploadTaskStatus::Completed | UploadTaskStatus::RapidUploadSuccess => {
                    return Err(anyhow::anyhow!("ä»»åŠ¡å·²å®Œæˆ"));
                }
                UploadTaskStatus::Failed => {
                    // å…è®¸é‡è¯•å¤±è´¥çš„ä»»åŠ¡
                }
            }
            (task.local_path.clone(), task.remote_path.clone(), task.total_size)
        };

        // åŠ¨æ€è·å–ä¸Šä¼ æœåŠ¡å™¨åˆ—è¡¨
        match self.client.locate_upload().await {
            Ok(servers) => {
                if !servers.is_empty() {
                    self.server_health.update_servers(servers);
                }
            }
            Err(e) => {
                warn!("è·å–ä¸Šä¼ æœåŠ¡å™¨åˆ—è¡¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æœåŠ¡å™¨: {}", e);
            }
        }

        // æ ¹æ®æ¨¡å¼é€‰æ‹©å¯åŠ¨æ–¹å¼
        if self.use_scheduler && self.scheduler.is_some() {
            self.start_task_with_scheduler(task_id, &task_info, local_path, remote_path, total_size).await
        } else {
            self.start_task_standalone(task_id, &task_info).await
        }
    }

    /// è°ƒåº¦å™¨æ¨¡å¼å¯åŠ¨ä»»åŠ¡
    async fn start_task_with_scheduler(
        &self,
        task_id: &str,
        task_info: &dashmap::mapref::one::Ref<'_, String, UploadTaskInfo>,
        local_path: PathBuf,
        remote_path: String,
        total_size: u64,
    ) -> Result<()> {
        let scheduler = self.scheduler.as_ref().unwrap();

        // é¢„æ³¨å†Œæ£€æŸ¥
        if !scheduler.pre_register().await {
            // åŠ å…¥ç­‰å¾…é˜Ÿåˆ—è€Œä¸æ˜¯è¿”å›é”™è¯¯
            self.waiting_queue.write().await.push_back(task_id.to_string());

            info!(
                "ä¸Šä¼ ä»»åŠ¡ {} åŠ å…¥ç­‰å¾…é˜Ÿåˆ—ï¼ˆç³»ç»Ÿç­‰å¾…ï¼‰(æ´»è·ƒä»»åŠ¡æ•°å·²è¾¾ä¸Šé™: {})",
                task_id, self.max_concurrent_tasks()
            );
            return Ok(());
        }

        // å…‹éš†éœ€è¦çš„æ•°æ®
        let task = task_info.task.clone();
        let chunk_manager = task_info.chunk_manager.clone();
        let cancel_token = task_info.cancel_token.clone();
        let is_paused = task_info.is_paused.clone();
        let active_chunk_count = task_info.active_chunk_count.clone();
        let max_concurrent_chunks = task_info.max_concurrent_chunks;
        let uploaded_bytes = task_info.uploaded_bytes.clone();
        let last_speed_time = task_info.last_speed_time.clone();
        let last_speed_bytes = task_info.last_speed_bytes.clone();
        let server_health = self.server_health.clone();
        let client = self.client.clone();
        let scheduler = scheduler.clone();
        let task_id_string = task_id.to_string();
        let vip_type = self.vip_type;

        // åœ¨åå°æ‰§è¡Œ precreate å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
        tokio::spawn(async move {
            info!("å¼€å§‹å‡†å¤‡ä¸Šä¼ ä»»åŠ¡: {}", task_id_string);

            // æ ‡è®°ä¸ºä¸Šä¼ ä¸­
            {
                let mut t = task.lock().await;
                t.mark_uploading();
            }

            // 1. è®¡ç®— block_list
            let block_list = match crate::uploader::RapidUploadChecker::calculate_block_list(&local_path, vip_type).await {
                Ok(bl) => bl,
                Err(e) => {
                    error!("è®¡ç®— block_list å¤±è´¥: {}", e);
                    scheduler.cancel_pre_register();
                    let mut t = task.lock().await;
                    t.mark_failed(format!("è®¡ç®— block_list å¤±è´¥: {}", e));
                    return;
                }
            };

            // 2. é¢„åˆ›å»ºæ–‡ä»¶
            let precreate_response = match client.precreate(&remote_path, total_size, &block_list).await {
                Ok(resp) => resp,
                Err(e) => {
                    error!("é¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e);
                    scheduler.cancel_pre_register();
                    let mut t = task.lock().await;
                    t.mark_failed(format!("é¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e));
                    return;
                }
            };

            // æ£€æŸ¥ç§’ä¼ 
            if precreate_response.is_rapid_upload() {
                info!("ç§’ä¼ æˆåŠŸ: {}", remote_path);
                scheduler.cancel_pre_register();
                let mut t = task.lock().await;
                t.mark_rapid_upload_success();
                return;
            }

            let upload_id = precreate_response.uploadid.clone();
            if upload_id.is_empty() {
                error!("é¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid");
                scheduler.cancel_pre_register();
                let mut t = task.lock().await;
                t.mark_failed("é¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid".to_string());
                return;
            }

            // 3. åˆ›å»ºè°ƒåº¦ä¿¡æ¯å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
            let schedule_info = UploadTaskScheduleInfo {
                task_id: task_id_string.clone(),
                task: task.clone(),
                chunk_manager,
                server_health,
                client,
                local_path,
                remote_path: remote_path.clone(),
                upload_id: upload_id.clone(),
                total_size,
                block_list,
                cancellation_token: cancel_token,
                is_paused,
                is_merging: Arc::new(AtomicBool::new(false)),
                active_chunk_count,
                max_concurrent_chunks,
                uploaded_bytes,
                last_speed_time,
                last_speed_bytes,
            };

            if let Err(e) = scheduler.register_task(schedule_info).await {
                error!("æ³¨å†Œä»»åŠ¡åˆ°è°ƒåº¦å™¨å¤±è´¥: {}", e);
                scheduler.cancel_pre_register();
                let mut t = task.lock().await;
                t.mark_failed(format!("æ³¨å†Œä»»åŠ¡å¤±è´¥: {}", e));
                return;
            }

            info!("ä¸Šä¼ ä»»åŠ¡å·²æ³¨å†Œåˆ°è°ƒåº¦å™¨: {}", task_id_string);

            // æ³¨æ„ï¼šè°ƒåº¦å™¨ä¼šè‡ªåŠ¨å¤„ç†åˆ†ç‰‡ä¸Šä¼ å’Œå®Œæˆ
            // è¿™é‡Œä¸éœ€è¦ç­‰å¾…ï¼Œè°ƒåº¦å™¨ä¼šåœ¨æ‰€æœ‰åˆ†ç‰‡å®Œæˆåè°ƒç”¨ create_file
        });

        Ok(())
    }

    /// ç‹¬ç«‹æ¨¡å¼å¯åŠ¨ä»»åŠ¡
    async fn start_task_standalone(
        &self,
        task_id: &str,
        task_info: &dashmap::mapref::one::Ref<'_, String, UploadTaskInfo>,
    ) -> Result<()> {
        // å…‹éš†éœ€è¦çš„æ•°æ®
        let task = task_info.task.clone();
        let chunk_manager = task_info.chunk_manager.clone();
        let cancel_token = task_info.cancel_token.clone();
        let server_health = self.server_health.clone();
        let client = self.client.clone();

        // åˆ›å»ºä¸Šä¼ å¼•æ“
        let engine = UploadEngine::new(
            client,
            task.clone(),
            chunk_manager,
            server_health,
            cancel_token,
            self.vip_type,
        );

        // åœ¨åå°å¯åŠ¨ä¸Šä¼ 
        let task_id_clone = task_id.to_string();
        tokio::spawn(async move {
            info!("å¼€å§‹ä¸Šä¼ ä»»åŠ¡: {}", task_id_clone);

            match engine.upload().await {
                Ok(()) => {
                    info!("ä¸Šä¼ ä»»åŠ¡å®Œæˆ: {}", task_id_clone);
                }
                Err(e) => {
                    error!("ä¸Šä¼ ä»»åŠ¡å¤±è´¥: {}, é”™è¯¯: {}", task_id_clone, e);
                    let mut task = task.lock().await;
                    task.mark_failed(e.to_string());
                }
            }
        });

        Ok(())
    }

    /// æš‚åœä¸Šä¼ ä»»åŠ¡
    pub async fn pause_task(&self, task_id: &str) -> Result<()> {
        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        // è®¾ç½®æš‚åœæ ‡å¿—ï¼ˆè°ƒåº¦å™¨æ¨¡å¼ä½¿ç”¨ï¼‰
        task_info.is_paused.store(true, Ordering::SeqCst);

        let mut task = task_info.task.lock().await;

        match task.status {
            UploadTaskStatus::Uploading | UploadTaskStatus::CheckingRapid => {
                task.mark_paused();
                info!("æš‚åœä¸Šä¼ ä»»åŠ¡: {}", task_id);
                Ok(())
            }
            _ => Err(anyhow::anyhow!("ä»»åŠ¡å½“å‰çŠ¶æ€ä¸æ”¯æŒæš‚åœ")),
        }
    }

    /// æ¢å¤ä¸Šä¼ ä»»åŠ¡
    pub async fn resume_task(&self, task_id: &str) -> Result<()> {
        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        {
            let task = task_info.task.lock().await;
            if task.status != UploadTaskStatus::Paused {
                return Err(anyhow::anyhow!("ä»»åŠ¡ä¸æ˜¯æš‚åœçŠ¶æ€"));
            }
        }

        // æ¸…é™¤æš‚åœæ ‡å¿—ï¼ˆè°ƒåº¦å™¨æ¨¡å¼ä½¿ç”¨ï¼‰
        task_info.is_paused.store(false, Ordering::SeqCst);

        // é‡æ–°å¼€å§‹ä»»åŠ¡
        self.start_task(task_id).await
    }

    /// å–æ¶ˆä¸Šä¼ ä»»åŠ¡
    pub async fn cancel_task(&self, task_id: &str) -> Result<()> {
        // ä»ç­‰å¾…é˜Ÿåˆ—ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        {
            let mut queue = self.waiting_queue.write().await;
            queue.retain(|id| id != task_id);
        }

        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        // å‘é€å–æ¶ˆä¿¡å·
        task_info.cancel_token.cancel();

        // å¦‚æœä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼ï¼Œä¹Ÿä»è°ƒåº¦å™¨å–æ¶ˆ
        if let Some(scheduler) = &self.scheduler {
            scheduler.cancel_task(task_id).await;
        }

        // æ›´æ–°ä»»åŠ¡çŠ¶æ€
        let mut task = task_info.task.lock().await;
        task.mark_failed("ç”¨æˆ·å–æ¶ˆ".to_string());

        info!("å–æ¶ˆä¸Šä¼ ä»»åŠ¡: {}", task_id);

        drop(task);
        drop(task_info);

        // å°è¯•å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        self.try_start_waiting_tasks().await;

        Ok(())
    }

    /// åˆ é™¤ä¸Šä¼ ä»»åŠ¡
    pub async fn delete_task(&self, task_id: &str) -> Result<()> {
        // ä»ç­‰å¾…é˜Ÿåˆ—ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        {
            let mut queue = self.waiting_queue.write().await;
            queue.retain(|id| id != task_id);
        }

        // å…ˆå–æ¶ˆä»»åŠ¡
        if let Some(task_info) = self.tasks.get(task_id) {
            task_info.cancel_token.cancel();
        }

        // å¦‚æœä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼ï¼Œä¹Ÿä»è°ƒåº¦å™¨ç§»é™¤
        if let Some(scheduler) = &self.scheduler {
            scheduler.cancel_task(task_id).await;
        }

        // ç§»é™¤ä»»åŠ¡
        self.tasks.remove(task_id);

        info!("åˆ é™¤ä¸Šä¼ ä»»åŠ¡: {}", task_id);

        // å°è¯•å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        self.try_start_waiting_tasks().await;

        Ok(())
    }

    /// è·å–ä»»åŠ¡çŠ¶æ€
    pub async fn get_task(&self, task_id: &str) -> Option<UploadTask> {
        let task_info = self.tasks.get(task_id)?;
        let task = task_info.task.lock().await;
        Some(task.clone())
    }

    /// è·å–æ‰€æœ‰ä»»åŠ¡
    pub async fn get_all_tasks(&self) -> Vec<UploadTask> {
        let mut tasks = Vec::new();

        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            tasks.push(task.clone());
        }

        // æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
        tasks.sort_by(|a, b| b.created_at.cmp(&a.created_at));

        tasks
    }

    /// è·å–æ´»è·ƒä»»åŠ¡æ•°
    pub fn active_task_count(&self) -> usize {
        let mut count = 0;
        for entry in self.tasks.iter() {
            // è¿™é‡Œä½¿ç”¨ try_lock é¿å…é˜»å¡
            if let Ok(task) = entry.task.try_lock() {
                if matches!(
                    task.status,
                    UploadTaskStatus::Uploading | UploadTaskStatus::CheckingRapid
                ) {
                    count += 1;
                }
            }
        }
        count
    }

    /// æ¸…é™¤å·²å®Œæˆçš„ä»»åŠ¡
    pub async fn clear_completed(&self) -> usize {
        let mut removed = 0;
        let mut to_remove = Vec::new();

        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            if matches!(
                task.status,
                UploadTaskStatus::Completed | UploadTaskStatus::RapidUploadSuccess
            ) {
                to_remove.push(entry.key().clone());
            }
        }

        for task_id in to_remove {
            self.tasks.remove(&task_id);
            removed += 1;
        }

        info!("æ¸…é™¤äº† {} ä¸ªå·²å®Œæˆçš„ä¸Šä¼ ä»»åŠ¡", removed);
        removed
    }

    /// æ¸…é™¤å¤±è´¥çš„ä»»åŠ¡
    pub async fn clear_failed(&self) -> usize {
        let mut removed = 0;
        let mut to_remove = Vec::new();

        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            if matches!(task.status, UploadTaskStatus::Failed) {
                to_remove.push(entry.key().clone());
            }
        }

        for task_id in to_remove {
            self.tasks.remove(&task_id);
            removed += 1;
        }

        info!("æ¸…é™¤äº† {} ä¸ªå¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡", removed);
        removed
    }

    /// å¼€å§‹æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
    pub async fn start_all_pending(&self) -> Result<usize> {
        let mut started = 0;
        let mut pending_ids = Vec::new();

        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            if matches!(task.status, UploadTaskStatus::Pending) {
                pending_ids.push(entry.key().clone());
            }
        }

        for task_id in pending_ids {
            if let Err(e) = self.start_task(&task_id).await {
                warn!("å¯åŠ¨ä»»åŠ¡å¤±è´¥: {}, é”™è¯¯: {}", task_id, e);
            } else {
                started += 1;
            }
        }

        info!("å¯åŠ¨äº† {} ä¸ªå¾…å¤„ç†çš„ä¸Šä¼ ä»»åŠ¡", started);
        Ok(started)
    }

    /// å°è¯•ä»ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨ä»»åŠ¡
    async fn try_start_waiting_tasks(&self) {
        if !self.use_scheduler {
            return;
        }

        let scheduler = match &self.scheduler {
            Some(s) => s,
            None => return,
        };

        loop {
            // æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²ä½ç½®
            let active_count = scheduler.active_task_count().await;
            if active_count >= self.max_concurrent_tasks() {
                break;
            }

            // ä»ç­‰å¾…é˜Ÿåˆ—å–å‡ºä»»åŠ¡
            let task_id = {
                let mut queue = self.waiting_queue.write().await;
                queue.pop_front()
            };

            match task_id {
                Some(id) => {
                    info!("ä»ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨ä¸Šä¼ ä»»åŠ¡: {}", id);
                    if let Err(e) = self.start_task(&id).await {
                        error!("å¯åŠ¨ç­‰å¾…ä¸Šä¼ ä»»åŠ¡å¤±è´¥: {}, é”™è¯¯: {}", id, e);
                    }
                }
                None => break, // é˜Ÿåˆ—ä¸ºç©º
            }
        }
    }

    /// å¯åŠ¨åå°ç›‘æ§ä»»åŠ¡ï¼šå®šæœŸæ£€æŸ¥å¹¶å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
    ///
    /// è¿™ç¡®ä¿äº†å½“æ´»è·ƒä»»åŠ¡è‡ªç„¶å®Œæˆæ—¶ï¼Œç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡èƒ½è¢«è‡ªåŠ¨å¯åŠ¨
    fn start_waiting_queue_monitor(&self) {
        let waiting_queue = self.waiting_queue.clone();
        let scheduler = match &self.scheduler {
            Some(s) => s.clone(),
            None => return,
        };
        let tasks = self.tasks.clone();
        let client = self.client.clone();
        let server_health = self.server_health.clone();
        let vip_type = self.vip_type;
        let max_concurrent_tasks = self.max_concurrent_tasks.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(3));

            loop {
                interval.tick().await;

                // æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…ä»»åŠ¡
                let has_waiting = {
                    let queue = waiting_queue.read().await;
                    !queue.is_empty()
                };

                if !has_waiting {
                    continue;
                }

                // æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²ä½ç½®
                let active_count = scheduler.active_task_count().await;
                if active_count >= max_concurrent_tasks.load(Ordering::SeqCst) {
                    continue;
                }

                // å°è¯•å¯åŠ¨ç­‰å¾…ä»»åŠ¡
                loop {
                    // å…ˆé¢„æ³¨å†Œï¼ŒæˆåŠŸæ‰ç»§ç»­
                    if !scheduler.pre_register().await {
                        break;
                    }

                    let task_id = {
                        let mut queue = waiting_queue.write().await;
                        queue.pop_front()
                    };

                    match task_id {
                        Some(id) => {
                            info!("ğŸ”„ åå°ç›‘æ§ï¼šä»ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨ä¸Šä¼ ä»»åŠ¡ {} (å·²é¢„æ³¨å†Œ)", id);

                            // è·å–ä»»åŠ¡ä¿¡æ¯
                            let task_info_opt = tasks.get(&id);
                            if let Some(task_info) = task_info_opt {
                                // è·å–ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
                                let (local_path, remote_path, total_size) = {
                                    let task = task_info.task.lock().await;
                                    (task.local_path.clone(), task.remote_path.clone(), task.total_size)
                                };

                                // å…‹éš†éœ€è¦çš„æ•°æ®
                                let task = task_info.task.clone();
                                let chunk_manager = task_info.chunk_manager.clone();
                                let cancel_token = task_info.cancel_token.clone();
                                let is_paused = task_info.is_paused.clone();
                                let active_chunk_count = task_info.active_chunk_count.clone();
                                let max_concurrent_chunks = task_info.max_concurrent_chunks;
                                let uploaded_bytes = task_info.uploaded_bytes.clone();
                                let last_speed_time = task_info.last_speed_time.clone();
                                let last_speed_bytes = task_info.last_speed_bytes.clone();

                                drop(task_info); // é‡Šæ”¾ DashMap å¼•ç”¨

                                let server_health_clone = server_health.clone();
                                let client_clone = client.clone();
                                let scheduler_clone = scheduler.clone();
                                let task_id_clone = id.clone();

                                // åœ¨åå°æ‰§è¡Œ precreate å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
                                tokio::spawn(async move {
                                    info!("åå°ç›‘æ§ï¼šå¼€å§‹å‡†å¤‡ä¸Šä¼ ä»»åŠ¡: {}", task_id_clone);

                                    // æ ‡è®°ä¸ºä¸Šä¼ ä¸­
                                    {
                                        let mut t = task.lock().await;
                                        t.mark_uploading();
                                    }

                                    // 1. è®¡ç®— block_list
                                    let block_list = match crate::uploader::RapidUploadChecker::calculate_block_list(&local_path, vip_type).await {
                                        Ok(bl) => bl,
                                        Err(e) => {
                                            error!("åå°ç›‘æ§ï¼šè®¡ç®— block_list å¤±è´¥: {}", e);
                                            scheduler_clone.cancel_pre_register();
                                            let mut t = task.lock().await;
                                            t.mark_failed(format!("è®¡ç®— block_list å¤±è´¥: {}", e));
                                            return;
                                        }
                                    };

                                    // 2. é¢„åˆ›å»ºæ–‡ä»¶
                                    let precreate_response = match client_clone.precreate(&remote_path, total_size, &block_list).await {
                                        Ok(resp) => resp,
                                        Err(e) => {
                                            error!("åå°ç›‘æ§ï¼šé¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e);
                                            scheduler_clone.cancel_pre_register();
                                            let mut t = task.lock().await;
                                            t.mark_failed(format!("é¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e));
                                            return;
                                        }
                                    };

                                    // æ£€æŸ¥ç§’ä¼ 
                                    if precreate_response.is_rapid_upload() {
                                        info!("åå°ç›‘æ§ï¼šç§’ä¼ æˆåŠŸ: {}", remote_path);
                                        scheduler_clone.cancel_pre_register();
                                        let mut t = task.lock().await;
                                        t.mark_rapid_upload_success();
                                        return;
                                    }

                                    let upload_id = precreate_response.uploadid.clone();
                                    if upload_id.is_empty() {
                                        error!("åå°ç›‘æ§ï¼šé¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid");
                                        scheduler_clone.cancel_pre_register();
                                        let mut t = task.lock().await;
                                        t.mark_failed("é¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid".to_string());
                                        return;
                                    }

                                    // 3. åˆ›å»ºè°ƒåº¦ä¿¡æ¯å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
                                    let schedule_info = UploadTaskScheduleInfo {
                                        task_id: task_id_clone.clone(),
                                        task: task.clone(),
                                        chunk_manager,
                                        server_health: server_health_clone,
                                        client: client_clone,
                                        local_path: local_path.to_path_buf(),
                                        remote_path: remote_path.to_string(),
                                        upload_id: upload_id.clone(),
                                        total_size,
                                        block_list,
                                        cancellation_token: cancel_token,
                                        is_paused,
                                        is_merging: Arc::new(AtomicBool::new(false)),
                                        active_chunk_count,
                                        max_concurrent_chunks,
                                        uploaded_bytes,
                                        last_speed_time,
                                        last_speed_bytes,
                                    };

                                    if let Err(e) = scheduler_clone.register_task(schedule_info).await {
                                        error!("åå°ç›‘æ§ï¼šæ³¨å†Œä»»åŠ¡åˆ°è°ƒåº¦å™¨å¤±è´¥: {}", e);
                                        scheduler_clone.cancel_pre_register();
                                        let mut t = task.lock().await;
                                        t.mark_failed(format!("æ³¨å†Œä»»åŠ¡å¤±è´¥: {}", e));
                                        return;
                                    }

                                    info!("åå°ç›‘æ§ï¼šä¸Šä¼ ä»»åŠ¡ {} å·²æ³¨å†Œåˆ°è°ƒåº¦å™¨", task_id_clone);
                                });
                            } else {
                                // ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå–æ¶ˆé¢„æ³¨å†Œ
                                warn!("åå°ç›‘æ§ï¼šä»»åŠ¡ {} ä¸å­˜åœ¨ï¼Œå–æ¶ˆé¢„æ³¨å†Œ", id);
                                scheduler.cancel_pre_register();
                            }
                        }
                        None => {
                            // é˜Ÿåˆ—ä¸ºç©ºï¼Œå–æ¶ˆé¢„æ³¨å†Œ
                            scheduler.cancel_pre_register();
                            break;
                        }
                    }
                }
            }
        });
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::auth::UserAuth;
    use std::fs;
    use std::io::Write;
    use tempfile::{NamedTempFile, TempDir};
    use crate::AppConfig;

    fn create_test_manager() -> UploadManager {
        let user_auth = UserAuth::new(123456789, "test_user".to_string(), "test_bduss".to_string());
        let client = NetdiskClient::new(user_auth.clone()).unwrap();
        let config = AppConfig::default();
        UploadManager::new_with_config(client, &user_auth, &config.upload)
    }

    #[tokio::test]
    async fn test_create_task() {
        let manager = create_test_manager();

        // åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        let mut temp_file = NamedTempFile::new().unwrap();
        let content = b"Test file content for upload";
        temp_file.write_all(content).unwrap();
        temp_file.flush().unwrap();

        let result = manager
            .create_task(
                temp_file.path().to_path_buf(),
                "/test/upload.txt".to_string(),
            )
            .await;

        assert!(result.is_ok());

        let task_id = result.unwrap();
        let task = manager.get_task(&task_id).await;

        assert!(task.is_some());
        let task = task.unwrap();
        assert_eq!(task.status, UploadTaskStatus::Pending);
        assert_eq!(task.total_size, content.len() as u64);
    }

    #[tokio::test]
    async fn test_get_all_tasks() {
        let manager = create_test_manager();

        // åˆ›å»ºå¤šä¸ªä¸´æ—¶æ–‡ä»¶å’Œä»»åŠ¡
        for i in 0..3 {
            let mut temp_file = NamedTempFile::new().unwrap();
            temp_file.write_all(format!("Content {}", i).as_bytes()).unwrap();
            temp_file.flush().unwrap();

            manager
                .create_task(
                    temp_file.path().to_path_buf(),
                    format!("/test/file{}.txt", i),
                )
                .await
                .unwrap();
        }

        let tasks = manager.get_all_tasks().await;
        assert_eq!(tasks.len(), 3);
    }

    #[tokio::test]
    async fn test_delete_task() {
        let manager = create_test_manager();

        let mut temp_file = NamedTempFile::new().unwrap();
        temp_file.write_all(b"Test content").unwrap();
        temp_file.flush().unwrap();

        let task_id = manager
            .create_task(
                temp_file.path().to_path_buf(),
                "/test/delete.txt".to_string(),
            )
            .await
            .unwrap();

        // ç¡®è®¤ä»»åŠ¡å­˜åœ¨
        assert!(manager.get_task(&task_id).await.is_some());

        // åˆ é™¤ä»»åŠ¡
        manager.delete_task(&task_id).await.unwrap();

        // ç¡®è®¤ä»»åŠ¡å·²åˆ é™¤
        assert!(manager.get_task(&task_id).await.is_none());
    }

    #[tokio::test]
    async fn test_create_folder_task() {
        let manager = create_test_manager();

        // åˆ›å»ºæµ‹è¯•æ–‡ä»¶å¤¹ç»“æ„
        let temp_dir = TempDir::new().unwrap();
        let root = temp_dir.path();

        // åˆ›å»ºæ–‡ä»¶
        fs::write(root.join("file1.txt"), "content1").unwrap();
        fs::write(root.join("file2.txt"), "content2").unwrap();

        // åˆ›å»ºå­ç›®å½•å’Œæ–‡ä»¶
        fs::create_dir(root.join("subdir")).unwrap();
        fs::write(root.join("subdir/file3.txt"), "content3").unwrap();

        // åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡
        let result = manager
            .create_folder_task(root, "/test/folder".to_string(), None)
            .await;

        assert!(result.is_ok());

        let task_ids = result.unwrap();
        assert_eq!(task_ids.len(), 3, "åº”è¯¥åˆ›å»º3ä¸ªä¸Šä¼ ä»»åŠ¡");

        // éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½å·²åˆ›å»º
        let all_tasks = manager.get_all_tasks().await;
        assert_eq!(all_tasks.len(), 3);

        // éªŒè¯ä»»åŠ¡çŠ¶æ€
        for task in all_tasks {
            assert_eq!(task.status, UploadTaskStatus::Pending);
            assert!(task.remote_path.starts_with("/test/folder/"));
        }
    }

    #[tokio::test]
    async fn test_create_folder_task_empty_folder() {
        let manager = create_test_manager();

        // åˆ›å»ºç©ºæ–‡ä»¶å¤¹
        let temp_dir = TempDir::new().unwrap();

        // å°è¯•åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡
        let result = manager
            .create_folder_task(temp_dir.path(), "/test/empty".to_string(), None)
            .await;

        assert!(result.is_err());
        assert!(result
            .unwrap_err()
            .to_string()
            .contains("æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–æ— å¯ä¸Šä¼ æ–‡ä»¶"));
    }

    #[tokio::test]
    async fn test_create_batch_tasks() {
        let manager = create_test_manager();

        // åˆ›å»ºå¤šä¸ªä¸´æ—¶æ–‡ä»¶
        let mut temp_files = Vec::new();
        for i in 0..3 {
            let mut temp_file = NamedTempFile::new().unwrap();
            temp_file
                .write_all(format!("Content {}", i).as_bytes())
                .unwrap();
            temp_file.flush().unwrap();
            temp_files.push(temp_file);
        }

        // å‡†å¤‡æ‰¹é‡ä»»åŠ¡
        let files: Vec<(PathBuf, String)> = temp_files
            .iter()
            .enumerate()
            .map(|(i, f)| (f.path().to_path_buf(), format!("/test/file{}.txt", i)))
            .collect();

        // æ‰¹é‡åˆ›å»ºä»»åŠ¡
        let result = manager.create_batch_tasks(files).await;

        assert!(result.is_ok());

        let task_ids = result.unwrap();
        assert_eq!(task_ids.len(), 3);

        // éªŒè¯æ‰€æœ‰ä»»åŠ¡
        let all_tasks = manager.get_all_tasks().await;
        assert_eq!(all_tasks.len(), 3);
    }
}
